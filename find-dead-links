#!/usr/bin/env python3

import requests 
import sys
from bs4 import BeautifulSoup
from pathlib import Path
from sys import argv

searchedLinks= []
deadLinks= []
fdlProg = Path(argv[0]).stem

def searchLink(url, linkDepth=0):
    try:
        r = requests.get(url)
        searchedLinks.append(url)
        soup = BeautifulSoup(r.text, features='html.parser')
        for link in searchedLinks:
            if r.status_code not in [200,302]:
                deadLinks.append(url)
                print(deadLinks[-1])
                print('Bad link')
            else:
                print('Good link')
    except:
        deadLinks.append(url)
if len(argv) not in [2,3]:
    print('Usage: %s <url>' % fdlProg)
    print('Usage: %s -<depth> <url>' % fdlProg)
    exit(1)
depth = 0
url = ''
for arg in argv:
    if arg.startswith('-'):
        try:
            depth = int(arg[1:])
        except ValueError:
            print('Invalid value for link depth: %s' % arg)
    else:
        url = arg

